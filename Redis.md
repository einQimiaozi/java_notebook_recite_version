## 常见数据类型

1.String：二进制安全(就是可以表示任何数据)，最大上限512m，也叫sds，本质是个可以动态扩容的byte数组，每次扩容大小为2n+1

2.Hash：kv集合，String的kv映射，适合存储对象

3.Set：无序集合，底层实现是value为null的HashMap，通过计算Hash值快速重排和快速判断成员是否在集合内，适用于需要取交集的场景，比如共同好友之类的

4.sorted Set:有序集合，底层使用hashmap实现，每个元素对应一个score，依靠score排序，排序后的元素放在跳跃表里，即通过hashmap决定存储结构，通过跳跃表保持有序性，适用于用户评分榜(id:socre)

5.List：字符串双向链表，缓冲区的实现基础

6.zipList：当数据较少时可以用zipList代替List和Hash，zipList本质是个数组，结构如下

|zlbyte|zltail|zllen|数据本身|zlend|

- zlbyte:数据大小 4字节
- zltail：末尾指针(偏移量) 4字节
- zllen:数组长度 2字节
- zlend：结束符 1字节

## 关于String的实现

redis中的String又叫SDS(simple dynamic string),就是一个动态char数组

空间不足时会触发扩容，如果数组长度<1mb，则每次扩容2倍+1,如果大于等于1mb，则每次扩容当前长度+1mb+1

SDS通过一个len记录cha数组大小保证二进制而全，这样可以记录任何格式的数据，不需要考虑换行符等问题

## 跳跃表

多层链表，查询的时候可以一次性跳跃多个节点，实现O(logn)的查询速度，本质是用空间换时间

跳表的层级为1到n层，最下层（节点数量最多的一层）为n层，最上层为1，查询时从1层进入进行二分查找

跳表的插入操作：
  - 首先使用二分查找找到待插入节点在第一层的位置
  - 随机晋升节点（一般是50%的概率），每次晋升成功节点就会被在插入到i层（下一层）
  - 如果晋升到第1层时再次晋升成功，那么就会单独创建一个链表，改链表仅有当前插入节点一个节点，然后整个跳表的层数+1

![skip1](https://github.com/einQimiaozi/java_notebook_recite_version/blob/main/img/skip1.jpeg)

![skip2](https://github.com/einQimiaozi/java_notebook_recite_version/blob/main/img/skip2.jpeg)

图片转自知乎

为什么不用红黑树/avl：
  - 1.并发环境下调整节点的操作容易产生线程安全问题(所谓的支持无锁操作)
  - 2.跳跃表实现更简单
  - 3.不需要旋转节点，插入极快

## redis的acid

原子性：redis的事务不支持原子性，因为redis本质是单线程的，不像mysql一样会因为临界资源争用问题造成事务原子性破坏，一般redis中的原子性不满足是因为代码写错了，这一点redis认为不需要数据库来处理

一致性：同样因为redis单线程，所以能够保证一致性，就算事务提交中原子性被破坏，但是不会出现一致性问题，因为被破坏的原子性不会引起“单条数据状态不合法"

隔离性：单线程不讨论隔离性问题，redis必然满足隔离性

持久性：使用aof和rdb保证，如果redis使用单纯的内存模式而不持久化，则redis不保证持久性

## pub/sub

消息发布和消息订阅，在redis中，你可以对某一个key进行消息发布和订阅，当该key进行发布后，所有订阅它的客户端都会收到对应的消息。

## 持久化(RDB)

RDB是Redis用来进行持久化的一种方式，是把当前内存中的数据集快照写入磁盘，也就是 Snapshot 快照（数据库中所有键值对数据）。恢复时是将快照文件直接读到内存里。

1.自动触发：通过配置save命令到redis.conf配置文件中，根据save命令后接的参数决定自动触发的时间和频率

2.手动触发
  - 1.save命令:阻塞式持久化，该命令会调用主进程把数据库状态写入RDB命令文件(dump.rdb)中，文件创建完毕之前redis不能处理其他的任何请求和事务
  - 2.bgsave命令：非阻塞持久化，该命令会创建一个子进程(父进程的复制品)专门处理数据库状态的写入，全程只有fork父进程的时候才会有瞬间的阻塞

缺点：需要一定时间内做一次备份，如果redis意外down掉的话，就会丢失最后一次快照后的所有修改(数据有丢失)。对于数据完整性要求很严格的需求

## 持久化(AOF)

通过将数据库的操作记录写入AOF文件来完成持久化

1.append only file：该命令将操作写入appendonly.aof文件内，os在缓冲区满之后会一次性刷入磁盘(也就是说对于redis来说是写入磁盘，但是os实际上不会每次都写入磁盘)，使用主进程fork一个子进程来并发处理，将重写对服务器的影响降低到了最小。
  - no：每30秒同步一次
  - everysex：每秒同步一次
  - always：每接受到一条新命令就同步一次
  - aof缓冲区：子进程创建后如果主进程处理了新的命令，则会将该操作写入aof缓冲区，子进程会将缓冲区的内容也写入aof文件，保证重写的实时性

为什么要fork子进程而不是用子线程去做

子线程需要和主进程共享内存，备份时会copy一份数据库的副本到内存里，占用更多内存空间，而子线程则采用的是直接对主进程内存进行访问，访问时会把当前内存部分的页桢设置为可读状态，任何人不能修改，这样可以制造一份完美的备份快照，而如果主进程此时对数据进行修改，会触发一个异常，该异常会copy该页桢到一个新的可写页桢里，即copy on write，这样不会影响快照备份，之后再将该数据的引用连接到新的页桢里就ok了，整个过程本质上其实就是一个copy on write

## redis的事件处理模型

1.6.0之前的redis使用io多路复用处理事件，该模型被称为事件处理器，包含了多个socket管理客户端链接，io多路复用程序，文件事件分派器，事件处理器四个模块

2.执行流程：
  - 文件处理器基于io多路复用模型监听多个socket
  - 当socket的读/写/应答/关闭等操作任意之一就绪时，多路复用程序将socket通过事件分派处理器分派给与socket相关连的事件处理器进行处理

3.非阻塞执行流程(redis6.0后支持非阻塞，并发只存在于网络事件io，其他部分还是单线程，不存在线程安全问题)：
  - 主线程建立链接请求，获取socket放入全局等待读队列
  - 主线程处理完读事件之后通过RR策略将等待队列平均分给io线程们(socket和线程绑定)
  - 主线程阻塞，等待io线程读取socket完毕
  - io线程组并行对socket解析(只解析不执行)，主线程阻塞，解析全部完成后主线程执行所有请求命令，将数据写入缓冲区
  - 主线程阻塞等待socket回写完毕后解除等待队列和线程的绑定，清空等待队列

4.为什么不用多线程
  - redis的性能瓶颈不在cpu而在io和内存
  - 单线程容易编程和维护
  - 死锁和上下文切换会影响性能

5.为什么后来加入多线程
  - 加入的多线程只负责网络io，解决io瓶颈问题

## 事务指令

1.multi：标记事务块的开始，总是返回ok，redis会将后续命令加入到执行队列中再执行exec

2.watch：用于监听一个或多个key，如果事务exec之前该key被修改则触发事务打断，exec执行结果返回null

3.exec：执行所有被放入执行队列中的事务，执行结束后恢复正常链接状态，使用cas同步，执行成功则返回该队列中所有原子化事务的执行结果组成的数组，要注意的是，redis不保证原子性，也就是说队列中即便存在执行失败的事务，exec也会将其他事务执行完毕而不是全部不执行

4.discard：取消事务块内所有命令的执行，总是返回ok

redis的事务不支持rollback，不满足原子性和持久性

## key的过期删除策略(3+2+1)

redis使用key+该key的过期时间组成一个过期字典，通过查询该字典判断key是否过期，使用expire设置

1.定期删除：定期检查一部分key(key的选取是随机的)是否过期，需要人工设置检查频率，设置的好则能平衡cpu和内存的消耗，设计的不好会导致获取到一个已经过期的key

2.定时删除：创建多个定时器对所有key进行检查，一旦发现过期立刻删除，频繁删除不cpu友好，对内存友好

3.惰性删除：读取key时才检查是否过期，删除频率低对cpu友好，对内存不友好

4.redis默认使用定期删除+惰性删除，平衡cpu和内存，同时惰性删除可以避免获取到一个过期的key
所有
## 内存淘汰策略

1.volatile-lru：利用LRU算法移除最近使用较少的(only expire)

2.allkeys-lru：利用LRU算法移除最近使用较少的

3.volatile-random:瞎jb删(only expire)

4.allkeys-random:瞎jb删

5.volatile-ttl：优先移除快过期的(only expire)

6.noeviction:默认策略，oom后直接抛错误，别的什么也不做

## 缓存穿透

指用户不断查询缓存和数据库中不存在的数据，导致每次请求都会到达数据库，从而压跨数据库

解决方法：
  - 业务层校验：对明显有问题的查询直接拦截(比如自增主键小于0)
  - 将空结果短期缓存，下次查询时直接返回缓存
  - 布隆过滤器

## 缓存击穿

当热点key失效时依然有大量查询请求到达数据库，导致数据库被压跨(比如淘宝双11活动0点结束，在0点0分1秒时key失效，但依然会有大量请求)

解决方案：
  - 设置热点key永不过期
  - 对热点key根据业务场景定期更新
  - 互斥锁：当热点key第一次查询失效时先上锁，使其他请求sleep一段时间，该期间从数据库更新key到缓存然后再释放锁

## 缓存雪崩

缓存大面积失效，大量查询会直达数据库导致数据库被压跨

解决方案：
  - 设置均匀分布的数据有效期避免数据集体失效(失效时间后加入随机值也可以)
  - 提前预热：对将要到来的大量请求提前走一遍系统，提前缓存
  - 保证redis服务器高可用

## 布隆过滤器

布隆过滤器用来确定一个元素不在当前集合里or一个元素在当前集合中的概率

公式

![bulong](https://pic1.zhimg.com/80/v2-1ed5b79aa7ac2e9cd66c83690fdbfcf0_720w.jpg)

k 为哈希函数个数，m 为布隆过滤器长度，n 为插入的元素个数，p 为误报率，其中k和m需要我们通过设定n和p计算出来

原理：

布隆过滤器是一个bit数组

对于某个值使用多个不同的哈希函数生成多个哈希值，并对每个生成的哈希值指向的 bit 位置 1，比如如果使用3个哈希函数，则该值再布隆过滤器中会有三个bit位为1

如果使用布隆过滤器查询某个值时，对应的多个哈希函数中某一个指向的bit位为1(哪怕其他几个都是0)，那么该值必不存在与当前集合中

如果某个值的对应的多个哈希函数的bit位都为1,也只能说明该值可能在当前集合中(因为不同的多个key可能正好覆盖了当前key的多个bit位，这样当前key即便不存在，但是bit位可能也都是1)

## redis保证和其他db的一致性

1.读操作优先读redis，失效则访问其他数据库，并把读到的数据回写给redis

2.写操作时先写其他数据库，再写redis(mysql的话可以CRUD服务触发器，CRUD触发后直接写入redis，或者让redis解析binlog，根据binlog执行操作)

3.设定超时时间，超时则删除redis中对应的数据，这样最差的情况下在超时时间外，数据一致性也能得到保证

## 分布锁

概念：当多个进程不在同一个系统中，用分布式锁控制多个进程对资源的访问，保证只有一台服务器取到锁

分布锁的四个要求
  - 1.互斥性：懒得解释了
  - 2.安全性：锁只能被持有该锁的客户端删除，不能由其它客户端删除。
  - 3.死锁避免：对客户端释放锁的时间应做限制
  - 4.容错：过半节点挂掉时另一半节点仍能正常进行服务

redis分布式加锁原理：
  - 1.加锁的全过程使用一个lua脚本控制，因为加锁需要原子性操作，所以把一个加锁过程包在一个lua脚本里可以保证过程的原子性，锁中保存一个hash值和一个数量组成的结构体
  - 2.lua脚本首先根据当前客户端生成一个hash值，如果该hash值和锁结构中的hash值对应且可重入，或者是第一次加锁，则获取成功，数量+1，该锁默认持有30秒
  - 3.如果获取锁失败，客户端会得到当前持有锁客户端的剩余有效时间，并且不断循环再次尝试获取
  - 4.watch dog：客户端获取锁成功后会启动一个后台线程，10s查看一次当前锁状态，如果该客户端还在持有锁，则重制锁持有时间
  - 5.释放锁则数量-1，如果当前结构体中数量为0，则该hash值对应的客户端不再持有锁

redis分布式锁存在的问题：
  - 如果结点挂掉，则只能通过过期时间被动等待锁释放
  - 若挂掉的结点是master，此时客户端a从master请求锁成功，但是还没有复制到集群中其他的从节点上，那么新选举出来的master可能会直接丢失这个锁信息，或者让客户端b再次成功获取到该锁

红锁：redis分布式锁解决方案
  - 客户端向集群中n个master同时申请加锁（一般n=5）
  - 申请时使用一个客户端生成的固定key和随机value，这样每个master拿到的value就不一样了
  - 超过半数以上的master在自己的集群中复制完成并成功返回，客户端a加锁成功，否则失败
  - 这样当master挂掉时另一个客户端b来请求锁也没关系，因为客户端a如果加锁成功，至少有三台返回，客户端b就不可能拿到2台以上加锁成功的返回了
  - 红锁问题：
    - 1.开销大
    - 2.需要用户保证客户端向master申请加锁时每个申请到达的master不重复

## 主从

redis支持一个master node下配置多个slave node，采用异步方式复制数据

1.slave node：
  - slave node在做复制的时候不会阻塞master node的工作，也不会阻塞对自己的读请求，实际上slave node是通过一份旧的数据集提供对外的读服务，一旦复制完成，就会用新数据集代替旧数据集，代替期间会短暂的暂停对外的读服务
  - slave node的主要作用是用来做横向扩容，读写分离
  - slave node不能作为master node的热备份，因为一旦master node挂掉，重启后master node的数据一般都是空的，然后slave node自己再来个主动复制，slave node的数据也空了，大家一起对着空气做还原，这里建议的还是使用aof或rdb对master node做持久化备份，确保master node启动时是有数据的

2.主从复制的原理
  - slave初次连接master时会做全量复制
  - master通过后台线程写入rdb文件，并将写入rdb期间的新命令缓存一份到从服务器的内存中,这份内存叫做backlog，最后将rdb文件发送给slave，这里master支持无磁盘化复制，即rdb不写入磁盘，直接发送给slave
  - slave将rdb先写入磁盘，然后通过加载rdb文件到内存和backlog复制master
  - 主从复制是支持断点续传的
  - slave的过期key处理是由master发送del命令处理的，slave自己本身不处理过期key

3.断点续传的原理
  - run_id:每台服务器每次服务的身份id，也就是说同一台服务器如果启动两次不同的服务，那么run_id不同，一般用于区分master，因为master重启后的数据可能会被清空，这样slave就没有必要也不能进行断点续传和复制(这也是为什么不能通过ip地址判断)
  - master和slave都维护一个offset和run_id，offset用于记录当前复制的位置，和backllog搭配
  - 当master和slave重连后，slave先判断自己的run id和master的是否相同
  - 之后判断offset的位置在backlog中是否还有效，如果有效则重新从该位置开始续传(backlog是一个环状日志，如果主节点写入的内容超过backlog大小则会从头覆盖写入，当断网恢复之后，如果主节点写入了过多的数据导致从节点未复制的数据已经被覆盖了，那么offset就会失效，这就是offset失效的情况)
  - 如果上面两步任何一步不满足，就重新做全量备份

## 哨兵集群

哨兵集群是redis用于做集群架构监控管理的组建，一般至少3个哨兵组成，不保证数据零丢失，只保证redis集群的高可用性

1.哨兵功能：
  - 集群监控：监控master和slave是否正常运行
  - 消息通知：及时报告故障节点
  - 故障转移：通过投票判断master是否故障并将其转移到正常的slave节点上
  - 配置中心：通知客户端新的master地址(如果发生故障转移的话)

2.宕机：
  - 哨兵通过ping一个节点判断该节点是否宕机，这叫主观宕机，之后发起投票，其他哨兵都会去ping这个节点，并将结果互相交换，当多数哨兵的意见都是主观宕机后，就会转为客观宕机，客观宕机会触发故障转移和消息通知
  - 宕机后的选举：
    - 跟master断开时间较长的slave会被先排除
    - slave优先级最高的先选(这个优先级是设置的)
    - 优先级相同时，看offset，就是说复制master数据最多的slave当选
    - offset一样时，runid最小的当选
  - 选举后的切换
    - 哨兵a会去执行切换(哨兵a也是选出来的)，切换时会从新master那里得到一个version号
    - 如果哨兵a切换失败，则其他哨兵会等待最大时长后再选一个哨兵b去执行切换，得到的version和哨兵a的不一样！！！
    - 切换完成后，哨兵b会在本地更新master配置，并使用pub/sub将配置和version发给其他哨兵，其他哨兵根据version判断和自己当前的master配置版本是否一致，是否需要更新

3.自动发现：通过名为sentinel:hello的channel实现
  - 哨兵之间：通过pub/sub机制实现，通过sentinel给其他哨兵发布消息感知其他哨兵的存在，这里有两种发法，第一种是直接发给其他哨兵，另一种是通过监听自己监听的节点的channel中其他哨兵的消息来互相感知，哨兵之间会互相交换监控信息实现节点状态的同步共享
  - 哨兵和节点：通过向sentinel里发送一个带有自己ip，host和该节点runid的消息来监控该节点



