## Mysql结构

![arch](https://github.com/einQimiaozi/java_notebook_recite_version/blob/main/img/arch.jpeg)

查询缓存在mysql8.0之后被取消，一般认为数据库若不处于静态图状态则查询缓存命中率极低，不建议使用

## 基本数据类型

1.整型
  - 1.tinyint smalliont,meduimint,int
  - 2.bigint(用于记录大数)

2.浮点型
  - 1.float(8字节) double(16字节)
  - 2.decimal(大数，用于存储货币单位)

3.日期
  - 1.date，time，year
  - 2.timestamp(4字节，1970-2038年) datetime(8字节，一般比timestamp好用)

4.varchar
  - 用于存储可变长字符串，比定长更节省空间
  - 使用varchar(n)指定长度
  - 使用1到2个额外的字节记录字符串长度
  - 由于程度可变，需要update时做额外工作，会影响update效率
  - 适用场景：
  - 字符串列长度大于平均长度
  - 列的更新很少
  - 使用了像utf-8这样复杂的字符集

5.char

  - 定长
  - 适合存储短字符串

## Mysql的执行过程

1.客户端发送查询语句给服务器

2.服务器见检查缓存，根据命中情况决定返回数据or对sql进行解析

4.从优化器生成对应的执行计划

5.根据执行计划调用存储引擎的api查询

6.将结果返回给客户端

## Mysql三大范式

1.数据的每一行不可拆分

2.主键必须能够唯一的区分数据，即非主键依赖主键

3.非主键属性不能依赖与其他非主键属性，比如部门和经理两个属性，如果部门经理唯一的话，那么由部门就可以推出其经理，相当与存经理这个key本身是浪费了资源

## 事务的ACID

1.a-->原子性：一个事务是一个不可分割的工作单位，其中的操作要么都做，要么都不做，通过undo log来保障

2.c-->持久性：事务一旦提交，它对数据库的改变就应该是永久性的，通过redo log来保障

3.i-->隔离性:事务内部的操作与其他事务是隔离的，并发执行的各个事务之间不能互相干扰,通过锁和事物的隔离级别来保障

4.d-->一致性：事务执行结束后，数据库的完整性约束没有被破坏，事务执行的前后都是合法的数据状态，原子性、持久性和隔离性，都是为了保证数据库状态的一致性

## 事务隔离级别

- 读未提交：事务提交前其他事务就可以看到，读不加锁，写加共享锁，会导致脏读幻读
- 读提交：事务提交后其他事务才能看到，读加共享锁，写加排他锁，会导致幻读，不可重复读
- 可重复读：一个事务执行开启阶段会创建一个当前数据状态的静态视图，执行过程中所有的数据都以这个静态视图为准，读加共享锁，写加间隙排他锁(一种行锁)，会导致幻读，innodb的默认隔离级别
- 串行化：读加共享锁，写加排他锁，锁全部使用表锁

## 脏读 幻读 不可重复读

脏读：事务提交前其他线程读取了未提交的数据

幻读：事务a对数据库进行修改后事务b插入了新数据，事务a提交前看到了未被修改的新数据会以为是自己遗漏了修改

不可重复读：同一事务对同一数据在事务内的两次查询结果不同，通常是因为另一个线程在这期间对数据修改并提交导致的

## 索引

mysql索引采用b+tree结构，叶节点记录数据

![索引结构](https://github.com/einQimiaozi/java_notebook_recite_version/blob/main/img/index.jpeg)

b+树结构 层高:2-4  子节点数量：每个父节点下带该1200个 查询次数：最多三次  叶子节点这一层本身也是个链表 基本单位为page，page及其下级单位物理和逻辑空间都连续

主键索引：主键索引的叶子节点里存的是一个区

非主键索引：非主键索引的叶子节点里存的是主键索引，根据主键索引查找数据，也称为二级索引，会引发回表(非主键->主键的二次查询)，mysql使用覆盖索引机制尽可能避免回表以提高性能

唯一索引：能够唯一定位一条数据的索引，主键索引默认是唯一索引，但是唯一索引不一定是主键索引，因为主键索引不允许Null值，唯一索引允许(但是唯一索引不能重复，所以只能有一个Null值)

普通索引：不能够唯一定位一条数据的索引，无限制要求

联合索引：索引的字段并非单一，由多个字段组成，例如(a,b,c)，联合索引可以是主键索引，但是要注意，如果联合索引有序，那么它的排序是按照从左到右的优先级来的，比如a字段相同的情况下，才会考虑b字段的顺序，由于此性质，联合索引中的首个字段可以不用单独建立一个索引，同时联合索引在创建(a,b,c)时，实际上创建的是(a) (a,b) (a,b,c)这三种索引的查找支持

覆盖索引：在根据某个非主键索引查询某个字段时，如果该索引可以代表该字段，那么就不需要回表了，比如根据索引name查询身份证号(假设身份证号为主键索引)，此时只需要返回name中存的主键即可，不需要再次回表

最左前缀原则：叶子节点按照左->右的顺序存放，方便查询，在联合索引下，最左前缀原则的顺序是按照联合索引的左边->右的优先级考虑的

索引下推：对于数据的非主键不做回表，而是直接使用逻辑判断，不满足条件则跳过，举例 (a,20) 直接查询主键a的数据是否为20,不满足则跳过 (mysql5.6之前是先找主键为a的数据，然后再这堆数据里找id为20的数据)

全表扫描：当索引失效时，mysql会执行全表扫描，顺序是按照磁盘存储的顺序来的，也叫扫表(不走索引)

不走索引的情况：
  - 1.模糊查询(like %xxx)中的前模糊和全模糊是不走索引的
  - 2.在where条件上进行函数or运算会不走索引，因为这样会破坏索引的有序性(底层是b+树嘛)，但是如果是先进行运算再判断条件就可以走索引，因为这样不会破坏有序性，比如select name from table where id+1=11(不走索引) select name from table where id=10+1(走索引)
  - 3.在联合索引下，不符合最左前缀原则就不会走索引了，比如索引(a,b,c)，其中a,b走索引,a,c走索引(但是这里走的是a的索引，c不走)，abc也走索引(这里顺序无所谓,只要有a在就行)，单查a也走索引，但是单查b or c，都不走索引，查询bc或cb也不走
  - 4.字符串->数字的隐式转换不走索引，但是数字->字符串的转换走索引
  - 5.使用!=会不走索引，is null不走索引，因为这几种情况能命中的范围比较大，所以mysql会认为全表扫描更快
  - 6.如果where查询中包含了索引和非索引的字段并且使用了or，那么所有索引都走不了
  - 7.select * from xxx一般不走索引，除非你这个xxx表里只有一行数据

为什么使用b+树作为索引结构(b+树索引性能分析)：索引本身很大，不能全部存在内存里，所以每次实际上会去磁盘找，但磁盘的io性能和内存差距较大，所以每次实际上会把查找结果的数据和其左右两边的部分数据一起载入内存(所谓的磁盘预读，根据局部性原理，程序运行时，被用得到的数据附近的其他数据往往也会马上被用到)，减少磁盘io，mysql中使用b树可以让一个节点的阶数根据页的大小调整，使得一个页能够一次性读取更多数据，减少磁盘io，同时b+树的非叶子节点不存数据，所以相当与节点更多，层高更小，查询的速度会比b树更快，并而b+树的叶子节点中的关键字链式相接，查找失败后不需要中序回溯，只需要像链表一样顺序查找就可以，所以适合该需求

索引优化建议：
  - 1.使用自增主键维护叶节点有序性比每次排序效率更高
  - 2.对于普通索引，内部存储的是主键，所以主键越短，内存消耗越低
  - 3.如果一个字段不一定非要是唯一索引的话，尽量选择普通索引，因为普通索引和唯一索引的查询效率差距不大，但是普通索引可以使用change buffer这种优化策略

索引的存储：索引如果在内存中，它所在的page会被存放在一个叫buffer pool的地方，用于快速读取

## chang Buffer

1.概念：一个记录修改操作的Buffer，位置在Buffer Pool中，需要单独内存空间维护，默认是占buffer pool的50%大小，可以调整，上限最大不能超过buffer pool

2.作用：每次修改数据时如果待修改数据不在Buffer Pool中，则将修改命令写入change Buffer后结束即可，当下次访问该数据时将change Buffer中的命令一次性执行，减少磁盘IO，用空间换时间

3.不能使用的情况：
  - 原则：如果buffer pool中已经确定存在的数据，使用change buffer就没意义了
  - 原因：change buffer解决的是磁盘io和内存速度的差异过大的问题，所以如果不存在磁盘io这一步，那么change buffer不光无法加速，还会占用内存空间
  - 常见情况：主键索引和唯一索引，因为这两种索引需要将数据读入内存判断是否有重复，所以不需要使用change buffer，而普通索引使用change buffer会效果拔群


## MVCC(多版本并发控制)

![data](https://github.com/einQimiaozi/java_notebook_recite_version/blob/main/img/data.jpeg)

MVCC是维持一个数据的多个版本，使读写操作没有冲突的一个抽象概念，实际上在mysql中的实现就是快照读

innode数据行结构

DATA_TRX_ID:记录插入或更新的最后一个事务的id

DATA_ROLL_PTR：指向该行对应的回滚段的指针，该行所有的旧版本都在undolog上以链表形式保存，实际上该指针指向的就是这玩意

1.redolog:记录每次提交的数据(在xx表做了xx修改，物理日志)，结构是一个数据，通过头指针和尾指针维护写入位置，数组满了就刷盘然后清空刷盘成功的数据(定时刷入，没到时间先放到缓冲区)，指针后移，用于实现crash-safe(前滚操作)，保证持久化，innodb中才存在的日志

2.undolog：存放数据库修改前的数据，用于回滚操作，innode中才存在的日志，用于保证事务原子性和MVCC实现，内部就是一个由data_roll_ptr组成的链表日志，通过该链表可以回滚到不同的数据库版本

3.binlog(这个和mvcc关系不大)：和redolog差不多，区别在于binlog是逻辑日志，记录的是操作，一般用于人工回滚而不是mysql自动回滚，另外每次记录之后直接写入磁盘，性能消耗和还原能力都不如redo log，但是是mysql的原生日志，不挑引擎

undo log工作流程：
  - 1.开始事务
  - 2.记录数据行快照到undolog
  - 3.更新数据
  - 4.将undolog刷盘(这里有个优化，将多次io放入缓存中，之后随机将几次io捆绑成一次io刷盘)
  - 5.提交事务

mvcc：读不加锁，读写不冲突，适合读多写少的场景，读有两种模式(快照读->返回记录的当前版本，不加锁 当前读->返回记录的最新版本，加锁，保证其他线程不修改)，需要额外空间维护记录

当前读：通过加锁读取数据库最新版本

快照读：通过无锁操作读取数据，读到的有可能不是最新版本

mvcc的承诺：读写不互斥，读读不互斥，写写互斥阻塞

mvcc的实现原理：
  - 通过事务的data_trx_id判断事物是否可见，然后通过对应的data_roll_ptr找到可见的数据库版本，每个数据的这两个属性在做undolog备份的时候也会被一同存入undolog中
  - 在读提交或可重复读的隔离级别下，事务在开始时会生成一个当前数据库的静态视图，该视图有以下属性
    - trx_ids: 当前系统活跃(未提交)事务版本号集合
    - low_limit_id: 创建当前read view 时“当前系统最大事务版本号+1”
    - up_limit_id: 创建当前read view 时“系统正处于活跃事务最小版本号”
    - creator_trx_id: 创建当前read view的事务版本号
  - 也就是说，如果一个事务的data_trx_id在up_limit_id和low_limit_id之间，则其必然会显示在静态视图中，即对当前事务可见
  - 如果一个事务在up和low之间：
    - data_trx_id不在trx_ids中，则说明该事务已经在生成静态视图前被提交，那么也必然可见
    - data_trx_id在trx_ids中，则说明该事务到目前仍然活跃并未被提交，则不可见

两阶段提交：指的是redolog和binlog如果同时存在，则做备份的时候先做redolog备份，然后等待binlog备份完成，在一起提交，这样的好处是防止binlog和redolog记录不一致导致回滚的时候出现幽灵数据

## 锁

1.全局锁(FTWRL)：使整个数据库处于只读状态，常用与全库备份和不支持隔离级别的引擎做隔离，缺点是会造成数据库阻塞，引起主从延迟

2.表锁：对表加锁，开销小速度快并发度低，不会死锁，锁冲突概率高，表锁分为两类：表锁和元数据锁(MDL)，前者是标准的读写锁，后者是读写不互斥，但是修改表结构和读写互斥(比如加字段)

3.行锁：对行加锁，一切和表锁相反......

4.排他锁和共享锁：懒得解释了

6.间隙锁：在索引之间加锁，比如索引a，b，c，如果锁b，那么实际上锁是加在a b之间和b c之间的

7.意向锁：多粒度加锁，允许行锁和表锁同时存在，插入意向锁是一种表锁，本质上是一种处理表锁和行锁冲突的方法，举例 事务a锁了一行，事务b申请该行所在的表的表锁，这样表锁和行锁就发生了冲突，事务a在锁行之前需要申请意向锁加锁，事务b在申请表锁时如果发现意向锁被a持有了一个行锁，则阻塞自己对表锁的申请

锁队列：mysql中的读写锁也是读之间不互斥，但是mysql的锁本质上是在一个锁队列中的，读锁a->读锁a之间是没问题的，但是读锁a->元数据锁a之间会互斥，此时如果读锁a由于延迟问题发生了阻塞，此时元数据锁a也会阻塞，如果后面再来一个新的读锁a，那么这个读锁a会因为队列优先级低(直白点说就是来的晚顺序靠后)，而被之前的元数据锁a阻塞！！！所以不论读写尽量不要使用长事务，因为一旦一个长事务执行时间过长，那么后面只要有一个互斥的添加字段操作被阻塞，则整个数据库就会陷入全库无法读写的状态，如果此时客户端有重试机制，每次阻塞都会再起一个会话重新请求的话......后果不堪设想

两阶段锁协议：
  - mysql中一个事务如果持有了一把锁，那么它的持有时间点是需要使用时才加上，比如update时，但是只有事务提交后才会释放，而不是update结束后释放
  - 建议：如果一个事务中需要多把锁(比如要同时操作银行账户和用户已购买商品列表，这样就需要两把锁嘛)，那么尽量把最可能造成锁冲突的事务放到后面(因为两阶段锁协议)，比如在这个例子中，银行账户只需要操作自己的余额，但是商品除了用户自己的购买以外还要扣减商家的库存，如果同时有多个用户一起购买了这个商品那么就要考虑锁冲突的问题，所以比较好的做法是把操作银行账户的更新语句放到更新已购列表前

死锁：
  - 因为两阶段锁协议的存在，mysql中才会发生死锁，如果你把一个长事务切分成多个小的短事务并发执行，基本上绝对会遇到死锁，所以千万别这么干，正确的做法是循环执行，这样既可以避免长事务对后面事务的阻塞，又不会产生死锁，最坏的结果也就是执行返回的结果可能会被中间的一些删除或写入事务影响，但是不会引发性能问题
  - 通常的解决方法是使用mysql自带的主动死锁检测(时间复杂度O(n))或者设置超时中断，但前者时间复杂度太高，后者不好控制时间
  - 一个更好的方法是限制加锁顺序，这个方法不光在mysql中可以使用，任何涉及死锁的地方都可以使用

