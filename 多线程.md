## 线程状态切换

![state](https://github.com/einQimiaozi/java_notebook_recite_version/blob/main/img/thread_states.jfif)

dead是无法切换回任何状态的，被阻塞的任何状态是无法直接切换会running状态的

## 创建线程的三种方式

1.继承Thread类

```java
public class MyThread extends Thread {
  public void run() {
    重写run方法实现你需要的功能
  }
}
publuc class Main {
  public static void main(String[] args) {
    MyThread thread = new MyThread.start();
    thread.run();
  }
}
```

需要注意的是Thread实例的start在其生命周期里不能重复执行，只能执行一次！！！

2.实现Runnable接口

```java
public class MyThread implements Runnable {
  public void run() {
    同上
  }
}
public class Main {
  public static void main(String[] args) {
    MyThread thread = new MyThread();
    Thread t = new Thread(thread);
    t.run();
  } 
}
```

3.使用Callable和Future处理

Callable接口和Runnable的区别在于它一共了一个call()方法作为线程的执行体，该方法不同与run方法，它可以有返回值和抛出异常，其返回值为Future接口的实现类

Future的实现类为FutureTask，该类不光实现了Future还实现了Callable，因此可以作为Thread对象的实参，Callable返回结果也是通过FutureTask的get方法实现，该方法会阻塞主线程直到拿到结果为止

## wait和sleep的区别

两个都是阻塞当前线程，但是wait会释放锁权限，sleep不会释放，而是单纯的阻塞

## 线程池

1.四种线程池
  - newCachedThreadPool:可缓存线程池，工作线程数量无限，当线程空闲超过1分钟则该线程停止
  - newFixedThreadPool:指定线程池的数量，当工作线程数量超出指定容量，则放入池等待队列
  - newSingleThreadPool:只有一个线程的线程池
  - newScheduleThreadPool:容量定长，支持定时和周期性任务的执行，通过将任务添加到DeloyedWorkQueue队列中实现，该队列的头节点就是延迟期满的任务，用的时候出队即可
  
2.线程池的构造参数
  - corePoolsize：核心大小
  - maximumPoolsize：最大容量
  - keepAlive：空闲线程最大生存时间
  - unit：时间单位
  - wordQueue：线程等待队列，一般由ArrayBlockingQueue,LinkedBlockingQueue和sycnhronousQueue实现
  - threadFactory：线程工厂，用于创建线程
  - handle：任务拒绝策略
    - 不执行该任务并返回错误
    - 不执行该任务并不返回任何信息
    - 尝试在线程池之外创建线程处理该任务
    - 丢弃等待队列最前面的任务，然后重新尝试执行任务
  
  注意，线程池在初始化时不论指定的容量和核心大小是多少，不会自动创建线程，即线程池实际大小为0,需要add一次创建一个，除非调用prestartAllCoreThreads()或者prestartCoreThread()方法提前创建
  
3.线程池的状态

  定义:
  
  ```java
  volatile int runState;
  ```
  
  - Running = 0:线程池未初始化
  - ShutDown = 1：让线程池处于关闭状态，即空闲线程全部销毁，在执行任务的线程执行完成之后销毁，最后关闭线程池(shutdown方法)
  - Stop = 2：让线程池处于立刻关闭状态，不论当前线程是否执行都强行销毁并关闭线程池(shutdownnow方法)
  - Terminated：线程全部销毁，等待队列清空，则当前线程池处于该状态
  
4.线程池的运行过程

线程池执行一个任务调用execute()方法或submit()方法，submit方法内部最终还是会调用execute方法，这两个方法的区别在于，execute只接收Runnable实现类，而submit还可以支持Callable实现类，进一步的说，execute方法没有返回值，但是submit有，返回结果为执行结果

  - 判断当前线程池中的线程数量是否超过核心大小，如果没有则new一个线程去处理任务，否则将该任务放入等待队列(源码中这里在execute方法里会判断一次，如果不超过核心大小会再加锁判断一次，因为有可能在这个过程中其他线程向线程池提交了任务)
  - 检查线程中是否有空闲时间超过keep_alive的，如果有则让它去等待队列里取任务执行，如果等待队列为空则销毁该线程，直到线程数量不大于核心大小为止(如果有线程依然空闲但是线程数量不超过核心大小的话就不管了，不用销毁)
  - 如果等待队列也满了，则尝试创建新线程去执行
  - 如果尝试失败(线程数量到达最大容量了)，则执行任务拒绝策略
  
5.addThread(Runnable firstTask)

  - 为提交的任务创建一个对应的Worker对象，调用线程工厂创建新的线程t
  - 将线程的引用赋给Worker的成员变量thread
  - 通过Worker的add(t)方法将对象加入到工作集中
  - 这里的Worker可以理解成一个线程的容器，是一个Runnable的实现类，所以可以像线程一样执行run方法，通过while循环不断执行getTask方法获取新任务(从等待队列中取)
  
6.等待队列
  - ArrayBlockingQueue：数组队列，创建时需要指定大小
  - LinkedBlockingQueue：链表队列
  - synchronousQueue：可以理解为陷阱队列，队列里只有一个元素，如果线程获取该队列的元素但队列为空，则该线程会被阻塞后放入队列，直到另一个线程获取它才会被释放
  
7.线程池的合理配置
  - cpu密集型：线程池大小=cpu数量+1
  - io密集型：线程池大小=cpu数量×2

## 锁

### 乐观锁和悲观锁

1.乐观锁：默认程序读时不会引起线程安全问题，读时其他线程不会修改数据，因此不加锁，写时会判断其他线程是否对数据进行过修改，使用cas或版本号机制(使用数据表记录数据被修改的次数version，每次更新时对照当前线程和数据库中的version是否相等)加锁

2.悲观锁：默认程度读时会引起线程安全问题，会修改数据，所以对这类操作进行加锁，常见的悲观锁有：synchronized，lock的实现类们等

### synchronized

1.对象头：synchronized使用的锁就存在java对象头中（这个对象头就是字面意思，对象的一个头部
  - make word：标记字段，存储对象运行时的很多自身数据(包括了下面的moniter)，用于实现轻量级锁
  - kclass pointer：类型指针，指向对象的类的元数据，通过类型指针可以判断这个对象是哪个类的实例

2.同步块实现原理
  - 使用moniterexit和moniterenter两个汇编指令实现，代表代码块的结束和开始，且两个指令必须同时呼应，不能只存在一个
  - jvm保证任何一个moniter监视器(可以理解为计数器)都有一个对象和其关联
  - 当对象持有moniter后会处于被锁定状态，线程执行到moniter指令前会尝试获取对象持有的moniter，即尝试获取锁
  - moniterenter：线程执行到该命令时，若当前对象的moniter=0或当前线程已经持有该对象的moniter(重入),则线程获取moniter成功并将其+1，否则线程阻塞
  - moniterexit：若持有moniter的线程执行到该命令时(必须是持有者哦)，moniter-1,当moniter==0时，该线程不再持有该对象的moniter，并将其所有权让给之前被阻塞的线程(非公平)

3.同步方法实现原理
  
  - 同步方法在编译时会被看作普通方法，只是在class文件的方法表中将方法的ACC_SYNCHRONIZED字段设置为1
  - 方法被调用时，调用指会检查ACC_SYNCHRONIZED字段，如果发现是同步方法，则线程会持有调用该方法的对象or该方法所属的class的moniter
  - 其他的部分就和同步块实现原理一样了，总结的话就是使用方法表来对同步方法进行特殊标识和检查以此来执行该对象关联方法的moniter机制

4.moniter的结构说明

  - moniter的起始地址存放在对象头的make word的lockword中
  - moniter的结构如下
  
  ![moniter](https://pcsdata.baidu.com/thumbnail/1fc13dd4am2ff63b0bfa29c5af354886?fid=1508469986-16051585-127307705054637&rt=pr&sign=FDTAER-yUdy3dSFZ0SVxtzShv1zcMqd-bGvw6ppsZAs6%2BxMLYg%2Fh2exVQGE%3D&expires=2h&chkv=0&chkbd=0&chkpc=&dp-logid=1447403155&dp-callid=0&time=1618999200&size=c1600_u1600&quality=100&vuk=-&ft=video)
  
  - 根据上面的结构可以看到，synchronized的非公平，并不是多个线程争同一把锁，而是任意唤醒一个线程来争用锁

5.synchronized的性质
  - 不分读写，也就是说读写都会独占锁
  - java内置关键字
  - 不需要主动释放锁，出现等程序不能正常运行的情况下，锁会自动释放
  - 中断：synchronized在等待获取时不会被中断，之后获取成功后并阻塞才可能被中断，Thread的interrupt方法只是设置synchronized的中断标志为true，中断需要抛出InterruptedException异常，所以一般要中断synchronized，最好用一个while循环去轮寻中断标志位(调用锁对象的isInterrupted()方法)，或者try catch捕获InterruptedException异常后处理

6.sycnhronized的锁升级
  
  synchronzied的锁会根据threadid来判断当前是否需要进行锁升级，一般不加synchronized就是无锁状态，升级后的锁不能降级，只能向上继续升级(也叫锁膨胀)，但偏向锁可以被重置为无锁状态

  - 偏向锁:synchronized的默认级别，synchronized会在第一次被线程持有时记录该线程的id，其他线程尝试获取时对比线程id，如果相同则不管，否则查看线程id对应的线程是否存活，不存活则释放锁，让其他线程争用，存活则快速查看该线程的栈帧id，确定是否还需要持有锁，如果需要，则阻塞线程1,将锁升级为轻量级锁，偏向锁由于其记录线程id，所以不会自动释放
  - 轻量级锁：由于偏向锁的锁操作其实是需要阻塞当前持有锁的线程的，所以需要切换用户态到内核态，如果线程持有锁时间不长，则会触发频繁切换，轻量级锁具体的做法是线程1将锁对象的对象头复制一份到自己的栈帧空间里，被称为锁记录，然后把锁对象对象头的内容替换为自己的锁记录，其他线程发现锁对象头被修改时就会开始自旋等待锁释放，适用与线程持有锁时间较短的场景
  - 重量级锁：轻量级锁出发的长时间自旋会消耗cpu，重量级锁的做法是当尝试获取锁的阻塞线程超过两个时，就将除了当前持有锁的线程以外的其他所有线程对该锁对象的获取全部阻塞，防止cpu空转，适用于线程数量多且持有锁时间较长的场景
  
  关于自旋锁：jvm会自动调整自旋锁每次旋转的次数，成功获取锁则下次增加，失败则下次减少，因为jvm希望自旋的获取不要每次都成功

7.锁粒度

  - 粗化：将多个连续的加锁解锁操作变成一个更大范围的锁，减少频繁加锁的消耗
  - 细化：尽可能喜欢同步块，让不必要的部分不加锁，缩短阻塞时间，如果存在锁竞争，那么等待锁的线程也能尽快拿到锁

8.锁消除：jvm在进行jit编译(实时编译)时通过对代码的逃逸分析去除没必要的锁，减少无意义的锁请求

9.适用场景
  - 资源竞争不激烈，因为sync是java内置关键字，经过了编译程序的优化，且在jvm上实现，不需要手动管理锁释放

### lock

1.lock是个接口，不是个类，你用的lock都是lock的实现类

2.lock不是java内置语言，需要你手动释放锁，否则会死锁，所以使用lock的实现类时，必须要try{...}finally{释放锁的代码},所以按道理来讲，lock在资源竞争激烈的情况下会比synchronized性能好一点

3.读写分离，读共享，写排他，默认为公平锁

4.常见lock方法
  - trylock()：会根据获取锁的结果返回是否成功
  - lockInteruptibly():可以中断正在等待获取锁的线程，会抛异常，所以必须用try

5.reetrantlock
  - 可重入锁，也是最常用的lock实现类，有也是唯一实现了lock()方法的lock实现类
  - 实现原理：
    - reetrantlock内部有一个集成自AQS的内部类SYNC，然后实现公平模式和非公平模式的两个内部类继承自SYNC
    - 调用lock()方法
    - lock()方法会调用acquire()方法，acquire()方法再去调用tryAcquire()方法ornonfairTryAcquire()方法，该方法是AQS的方法，可通过SYNC调用，获取state
    - 如果是非公平锁模式，调用nonfairTryAcquire()方法，该方法会通过AQS的getExclusiveOwnerThread()方法判断当前state同步状态的所有者是不是自己，如果是自己就+1,返回true，否则获取失败
    - 如果是公平模式，调用TryAcquire()方法，该方法会判断AQS的state是否为0,如果不为0或者为0但是等待队列中没有节点，那么获取锁，state+1并返回true，否则判断所有者是不是自己，如果是的话也返回true，否则获取失败
    - 简单来说reetrantlock的实现就是基于集成AQS框架，通过其同步状态state和等待队列实现的

6.适用场景：
  - 资源竞争激烈
  - 需要被中断
  - 同步时间有限制

### 锁类型

1.可重入锁：基于同一线程，对同一锁可重复获取(注意：不是基于同一方法！！！！)，sync和lock都是

2.可中断锁：线程a在等待获取线程b持有的锁时可以直接中断掉当前的等待，先去干别的，sync不是，lock是(注意：这里不是指线程a断掉线程b，不同子线程不能中断别人，指的是a断掉自己)

3.公平锁：多个线程争用同一锁时，获取的顺序=线程到来的顺序，lock是，sync不是

4.读写锁：读和写操作对资源的访问分成两个不同的锁，一般情况下(注意是一般)，读共享，写排他，lock中的读写锁类是，sync不是

## volatile

volatile本质不是一个锁，它比锁更轻量，并可以代替锁实现一些功能

1.语义：
  - 有序性：禁止指令重排序
  - 可见性：保证对该变量的修改立刻对其他线程可见
  - 注意，volatile不保证原子性，举例：线程a获取变量v后立刻被阻塞，线程b获取变量并对其进行自增操作，此时其他线程会立刻可见，使自己缓存的副本失效，但是线程a已经缓存到了v，所以此时线程a被唤醒后的后续操作是建立在v自增之前的

2.原理
  - 在汇编级代码下，volatile修饰的变量会被加入一个内存屏障----一个lock前缀指令
  - 该指令保证指令的顺序(禁止指令重排序)，强制对该变量的修改立刻写入主存并导致其他cpu中cpu缓存的副本失效(通过缓存一致性协议，即如果变量是共享的，则发出通知让其他cpu的缓存失效)，并相当与把变量声明为“共享”，最后做缓存锁定

3.适用场景
  - 不需要原子性操作
  - 对变量的修改不依赖当前值(就是说不依赖你代码里能看到的值，因为修改是可能被别的线程update成最新值了)
  - 该变量没有包含在具有其他变量的不变式中(？这句话我不太理解，按我的理解就是不变式要保证不可变，volatile可能被其他线程修改，所以不可以放到不变式里)

补充：intel手册对lock前缀的说明解释：
  - lock前缀实际上做的是总线锁定，即锁住除当前持有锁的cpu外所有其他cpu和内存之间的通信，这样做会导致效率降低
  - intel对lock进行了优化：如果要访问的内存区域在lock前缀指令执行期间已经在处理器内部的缓存中被锁定（即包含该内存区域的缓存行当前处于独占或以修改状态），并且该内存区域被完全包含在单个缓存行中，那么处理器将直接执行该指令，这种锁定叫做缓存锁定，缓存锁定将大大降低lock前缀指令的执行开销，但是当多处理器之间的竞争程度很高或者指令访问的内存地址未对齐时，仍然会锁住总线
  - lock前缀也是一种cpu锁：即处理器自动保证内存操作的原子性

## CAS

一种自旋锁的实现，通过比较当前得到的实际值和期望值判断是否获取到了同步状态

```java
public final boolean CompareAndSwap(int expect,int update) {
  // 通过unsafe调用JNI方法，若当前值和期望值相同就修改，否则自旋
  return unsafe.compareAdnswapInt(this,valueoffset,expect,update)
} 
```

1.原理
  - cas通过JNI实现，即调用底层cpu实现，使用汇编级别的cmpxchg指令(比较交换指令)
  - 多处理器下会对cmpxchg添加lock前缀，单处理器不存在执行顺序问题，所以不加前缀
  - 总结的话其实cas和volatile的原理差不多，只不过cas使用了cmpxchg指令

2.缺点
  - aba问题：
    - 即线程a通过cas修改了v之后又改回去了，对于其他线程而言，在cas下看到的结果就是v没被修改过，看上去似乎aba问题不存在隐患，其实不然，举例说明  
    - 解决方法：使用jdk1.5之后提供的AtomicstanpedReference方法，该方法会在满足cas条件的情况下使用原子方式对值进行更新
   
    ```
    三个线程a,b,c并发执行 操作账户余额 账户余额为100
    a->余额-50 期望值100
    b->余额-50 期望值100
    a.start()->a.run()->执行完毕
    b.start()->阻塞
    账户余额从100变为50，a执行完毕，b阻塞了，未执行扣款操作
    c->余额+50 期望值50
    c.start()->c.run()->执行完毕
    账户余额从50变回100,c执行完毕
    b->阻塞解除->b.run()->执行完毕
    注意！！！此时b的期望值依然满足！！！！
    账户余额从100变回50，b执行完毕
    问题：汇款而来的50元因为aba问题的存在不翼而非了！！！！！
    ```
  
  
  - 循环时间长：当cas长时间不成功的时候会一直自旋消耗cpu，解决方法是使用jvm提供的pause指令，使得cpu流水线执行延迟(不在以一条踩一条的方式执行)，避免退出循环时因执行顺序问题引发的cpu流水线被清空
  - 只能保证单个变量的原子性：解决方法是把多个变量变成一个变量(相加or封装到一个对象中这类方法都可以)

## Threadlocal

1.threadlocal是什么：threadlocal帮助线程维护自己的局部变量，在多线程下同一个变量通过threadlocal可以让线程拥有不同的线程私有的副本,副本的生命周期跟随threadlocal对象

2.ThreadlocalMap：
  - threadlocal的一个内部类，hash表，线程私有
  - 内部保存了一个entry数组，entry对象是一对键值对，key为Threadlocal对象的一个弱引用，value为该threadlocal对应的值
  - 由于entry是数组，所以其next并不像hashmap一样采用数组+链表的结构，而是通过nextIndex变量直接存放其next的一个引用，每个entry的hashcode从0开始，每创建一个Threadlocal，其hashcode+1640531527

3.public的set方法
  - 获取当前线程，通过当前线程拿到其对应的threadlocals变量，threadlocals就是ThreadlocalMap的一个实例对象
  - 如果threadlocals不为空，则将Threadlocal作为key，值为value，调用private的set方法插入kv
  - 如果为空，则创建ThreadlocalMap，并新建一个Entry放入该ThreadlocalMap，转到上一步

4.private的set方法
  - 根据传入的key的hashcode计算索引位置
  - 通过nextIndex遍历找到索引位置
  - 若遍历中出现hash冲突，则覆盖value
  - 如果遍历中出现的任何一个索引位置为空，说明当前位置的弱引用挂了，调用replaceStateEntry方法(用于记录位置)
  - 遍历结束(即entry[i]==null)时，找到索引位置，new一个Entry并插入key和value
  - 最后调用cleansomeslots方法，该方法会清空key的引用挂掉的entry，并判断是否需要扩容

5.get方法
  - 获取当前线程，拿到其threadlocals
  - 若threadlocals不为空，调用getEntry方法，通过当前threadlocal找到entry返回其value
  - 否则调用setInitialValue方法初始化

6.setInitialValue方法
  - 若threadlocals为空，new一个ThreadlocalMap对象作为threadlocals，传入key和value，value为null
  - 否则直接插入key=threadlocal，value=null

7.getEntry方法
  - 根据key的hashcode计算索引位置
  - 取出该位置的entry实例
  - 若hash冲突，则返回value
  - 否则调用getnEntryAfter方法继续向后查找

8.resize扩容：
  - 若清除key为null的entry后，容量超过阈值的3/4，则创建新表
  - 新表为旧表的2倍
  - 遍历旧表，根据hashcode计算每个entry新的索引位置，若发生hash冲突，则根据nextIndex采用线性定地法解决
  - 设置新的阈值，更新size，另引用旧表的变量table指向新表

注意：get，set等方法在遍历的时候如果发现key为null，则会调用ExpungeStateEntry方法清除，remove方法内部也是使用该方法一次性清理所有key为null的entry

9.内存泄漏问题

因为entry的key的引用是弱引用，所以会出现key=null但entry还在的情况，这样该entry就会无法访问，ExpungeStateEntry方法会清除这些没用的entry

但是ExpungeStateEntry方法方法只会在get，set，resize，remove等方法执行时被调用，如果长期不操作ThreadlocalMap，就会导致这些entry无法回收，造成内存泄漏，所以要经常调用remove方法手动清理

10.总结：
  - ThreadlocalMap的set，get等方法计算索引位置的方法和hashmap一样
  - key用弱引用的原因：因为方便key不被引用时及时回收，而value是当前线程中的某个变量副本，它是会被用到的！！！也就是说很可能你的key的引用被回收了，但是value在ThreadlocalMap之外还被引用，直接清理掉value会引发value为null的错误，所以只对key做弱引用

## AQS

抽象队列同步器，构造锁和各种同步组件的基础框架

1.重要方法和参数
  - volatile int state：同步状态，使用cas进行update，线程获取到同步状态后对state执行+1操作
  - volatile transient Node head：同步队列的头节点
  - volatile transient Node tail：同步队列的尾节点
  - tryAcquire：自定义方法,对同步状态独占式获取
  - tryRelease:自定义方法，对同步状态独占式释放
  - 上面两种方法后接shared就是共享式的独占和获取
  - isHeldExclusively：检查AQS是否被当前线程独占
  - exclusiveOwnerThread：当线程获取到同步状态后需要设置exclusiveOwnerThread为自己，表明当前同步状态的所有者是自己

2.同步队列：
  - 队列中的Node用来保存获取同步状态失败的线程，是一个双向链表，线程会变为Node后自旋尝试获取同步状态，如果自旋次数超过n次，则进入阻塞等待被唤醒
  - FIFO队列，这也是为什么由AQS实现的锁可以是公平锁
  - 一个节点的唤醒由其前继节点进行通知
  - 每个由AQS实现的lock，对应一个同步队列

3.条件变量和等待队列 ConditionObject
  - 每个条件变量实例必须和一个lock绑定，在代码中的体现就是条件变量的await和signal在加锁后，解锁前
  - 每个条件变量对应一个条件队列，该线程中任何一个条件变量调用await就会导致线程转换为Node被放入等待队列并阻塞
  - 此时如果另一个线程调用了相同的条件变量的signal，则被该条件变量await的线程会出队并被唤醒，也就是说，只要使用相同的条件变量，不同线程之间可以相互唤醒对方
  - 条件变量是什么：本质上就是一个唤醒其他线程的机制，他可以用来避免长时间的阻塞等待，例如：线程1获取到同步状态，执行任务中阻塞了，那么它可以让自己先await，让出同步状态，后面的其他线程执行完毕后，再唤醒它
  - 每个由AQS实现的lock，可以对应多个条件变量，所以每个lock其实可以有多个等待队列
  - 重点：一个线程只能存在与同步队列or等待队列，不能存在与同步队列and等待队列

4.共享模式
  - AQS的共享模式是指state的值的取值范围为[0,n]，每个线程获取同步状态后将该值+1
  - 每次获取只要state的值>=0就算获取成功(调用tryAcquireShared方法就行)
  - 如果失败，则转成Node尾插到同步队列中，自旋，还获取不到就阻塞
  - 通过前继节点唤醒后继节点

5.独占模式
  - state的范围为[0,1]，每次线程获取同步状态后将state+1,若state为1时则获取失败(调用tryAcquire方法)
  - 若获取失败则转成Node尾插到同步队列中，自旋，还获取不到就阻塞
  - 通过前继节点唤醒后继节点

6.中断
  - 独占和共享模式是不能中断的，理由和sync一样，如果想要实时响应中断，需要使用独占式可中断获取，并且该模式可以设置超时中断机制
  - 该模式会正在线程被中断是抛出异常并立刻返回，使用cancelAcquire方法取消同步状态

7.同步队列的底层实现

使用了LockSupport类，该类通过unsafe提供线程的阻塞和唤醒的公共方法

阻塞使用LockSupport.park(),唤醒使用LockSupport.unpark()

8.惊群

惊群指的是一次性唤醒过多线程导致的资源爆炸，同步队列和等待队列都提供signalAll方法唤醒全部队列中的Node，这样就有可能引起惊群，不建议使用该方法

## CountDownLatch

countdownLatch是由AQS实现的并发控制类，允许设置一个计数器，和一个等待队列，当队列中的线程数量>=计数器时一次性执行所有线程

1.底层实现：
  - 使用AQS框架的state作为计数器，共享模式
  - CountDownLatch构造时传入的计数器大小就是state共享模式能够获取的次数，使用CountDownLatch的sync方法和AQS进行交互
  - 每次获取state-1,当state小于0时，所有线程一起执行

2.await()：await方法会判断线程是否被打断，如果被打断则抛出中断异常，否则使用死循环阻塞线程，在死循环内不断判断state是否为0,如果为0则跳出循环不再阻塞

## CyclicBarrier

cyclicbarrier和countdownLatch差不多，下面说区别

1.cyclicbarrier支持运行时复位，就是运行时可以重新设置state，countdownLactch则不行

2.cyclicbarrier支持一个高级构造函数，可以传入一个Runnable实现类实例，当cyclicbarrier中的线程被唤醒时，先执行该实例的run方法，然后再执行其他线程

3.通过cyclicbarrier提供了一些高级方法，比如getNumberWaiting可以返回当前被阻塞的线程数量，isBroken可以知道被阻塞的线程是否被中断等


